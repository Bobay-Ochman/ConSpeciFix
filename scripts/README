####### File System
project
	genomes_proks.txt	#pulled from the NCBI database
	species.txt	#built from species.py, is the list of all species used



####### Preparing the data

Define the list of species to analyse (all the species with more than 15 complete genomes)

species.py	#defines species.txt

folders.py # Prepare one folder for each species. Within that folder, create the folders 'genes', 'genomes', 'align' and 'phylo'

download.py  # Download genomes

unzip.py # unzip all files

parse_gff_build.py	#	makes a list in 'todo/parse_gff.txt' with all parsing work that needs to be done

parse_gff_multi.py	#	creates n processes to parse the gff files listed in todo/parse_gff.txt
					#	- fasta files into a species folder. Two fasta files for each genome (One nucleotide file .fa and one protein file .prot).


####### Resampling analysis

usearch_build.py	#	makes a list in 'toDoList.txt' with all usearch Comps needing to be performed

usearch_multi.py    #	creates n processes to compare all the genome pairs with USEARCH

parse_multiple_usearch.py  # Find the pairs of orthologs
	-> creates input for MCL: PATH_TO_OUTPUT/sp/input.txt

********* transfer work to TACC

launch_mcl.py # Cluster orthologs into families
	-> creates input for get_core.py: PATH_TO_OUTPUT/sp/out.input_sp.txt.I12

get_core.py	# Define the core genome at 85% and extract core proteins into the folder 'align'
	-> generates output of core genomes and puts it in: PATH_TO_OUTPUT/sp/orthologs.txt
	-> also puts all orthologs genes and corresponding ids into  PATH_TO_OUTPUT/sp/align/ortho#
	-> also generates our list of "selected species" which will be used for the rest of the process
		
launch_mafft.py  # Align the core proteins with MAFFT

# wont't need the 'backtranslate.py' - Backtranslate the protein alignments into nucleotide alignments

concat85.py # Merge the core genes into a single alignment

raxml_distance.csh # Compute the distances with RAxML

sample.py # Remove nearly identical strains and generate random combinations of strains

calcHM.py # Compute the h/m ratios across all the combinations of strains


####### Graphs

graph.py # Generate the input files to generate the graphs

big_graph.py # Generate the script for R

big_graph.R # Generate the graphs


####### Exclusion Criterion

distrib.py

kmeans.py

split_kmaens.py

criterion.py

